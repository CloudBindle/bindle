---
# file: roles/seqware-worker-infrastructure/tasks/main.yml

- name:  Install Hadoop for a worker
  apt: name={{ item }} state=present update_cache=yes cache_valid_time=3600
  with_items: 
    - hadoop-0.20-mapreduce-tasktracker 
    - hadoop-hdfs-datanode
    - hadoop-client
    - hbase-regionserver

# This code is duplicated and should be refactored to a shared task, but still run after the dependencies above
# Need to figure out how to share tasks as opposed to roles
- name:  Set user groups
  user: name=mapred groups=seqware append=yes state=present
  user: name=seqware groups=mapred append=yes state=present
  user: name=mapred groups=hadoop append=yes state=present

- name:  Copy resources
  copy: 
    src: hadoop-files/conf.my_cluster
    dest: /etc/hadoop/
  register: hadoopconfig
  
- name:  Set up Hadoop configuration
  command: 'update-alternatives --install /etc/hadoop/conf hadoop-conf /etc/hadoop/conf.my_cluster 50'
  when: hadoopconfig.changed

- name:  Set up Hadoop configuration
  command: 'update-alternatives --set hadoop-conf /etc/hadoop/conf.my_cluster'
  when: hadoopconfig.changed
  
- name:  Start HDFS
  service: name=hadoop-hdfs-datanode state=started
  
- name:  Start TaskTracker
  service: name=hadoop-0.20-mapreduce-tasktracker state=started

# This is duplicated from common, need to share tasks
# TODO: need hdfs-site.xml configured properly using alternatives, but for now just copy it 
- name:  Copy HBase Config
  copy: 
    src: hadoop-files/conf.my_cluster/hbase-site.xml
    dest: /etc/hbase/conf/hbase-site.xml
  register: hbaseconfig
  
- name:  HBase
  service: name=hbase-regionserver state=started

- name:  Setup daemons to start on boot
  service: name={{ item }} state=started enabled=yes
  with_items: 
    - cron
    - hadoop-hdfs-datanode
    - hadoop-0.20-mapreduce-tasktracker

- name:  Install NFS
  apt: name={{ item }} state=present update_cache=yes cache_valid_time=3600
  register: nfs_installed
  with_items: 
    - rpcbind
    - nfs-common
    
- name:  Setup NFS - hosts.deny
  lineinfile: 
    dest: /etc/hosts.deny
    create: yes
    line: 'rpcbind : ALL' 
    state: present
    insertafter: EOF

- name:  Setup NFS - hosts.allow
  lineinfile: 
    dest: /etc/hosts.allow
    create: yes
    line: 'rpcbind : {{ hostvars["master"]["ansible_eth0"]["ipv4"]["address"] }}' 
    state: present
    insertafter: EOF

- name:  Mount NFS
  mount: name={{ item.name }} state=mounted src={{ item.src }} fstype=nfs4
  with_items:
     - { name: '/home', src: '{{ hostvars["master"]["ansible_eth0"]["ipv4"]["address"] }}:/home' }
     - { name: '/mnt/home', src: '{{ hostvars["master"]["ansible_eth0"]["ipv4"]["address"] }}:/mnt/home' }
     - { name: '/mnt/seqware-oozie', src: '{{ hostvars["master"]["ansible_eth0"]["ipv4"]["address"] }}:/mnt/seqware-oozie' }
     - { name: '/mnt/datastore', src: '{{ hostvars["master"]["ansible_eth0"]["ipv4"]["address"] }}:/mnt/datastore' }

- name:  Template init script
  template: src=hadoop-init-worker.j2 dest=/etc/init.d/hadoop-init
    
- name:  Set up init script permissions
  file: path=/etc/init.d/hadoop-init owner=root group=root mode=0755

- name:  Setup init script for boot
  service: name=hadoop-init enabled=yes